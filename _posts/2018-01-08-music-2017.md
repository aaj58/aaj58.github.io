---
layout: post
title: "Through the Headphones: Predicting My Liking of Music in 2017"
date: 2018-01-08
---
2017 was a strange year for music. Unlike the years before this where there were clear frontrunners for title of Album of the Year (see 2016’s Lemonade or 2015’s To Pimp a Butterfly), there were no cut and dry winners of 2017. I began writing for a music blog in June, and since, wrote blurbs for 80 songs from 22 different countries. Scoring on the blog operates on a scale of 0-10, so I decided to look back at my scoring patterns over the past six months. Clearly, this sample size is very small, so any conclusions should be taken with a grain of salt. Still, the new year is all about self-reflection, right?

The data set contains the following fields: song name, artist name, country (chosen based on the primary artist), primary genre, secondary genre, tertiary genre, release date, length in seconds, and my score. The genre fields were populated by me based on the genres I see each song/artist fitting into. All songs have a primary genre, but not all have a secondary or tertiary. Admittedly, there is some room for interpretation here, but I tried to keep it as consistent as possible.

First, my average score across all reviews was a 5.7. So, I skew slightly toward positivity in my ratings. Next logical step is to look at the score by genre. By the first, by the primary genre, my average scores were as follows.

Pop was my most reviewed genre, followed by Hip Hop and Country. However, genres with only a few reviews ended up bringing the highest scores: Soul, Alternative Rock, and Folk. Reviewing more songs tended to drive my scores toward my mean of 5.7, as expected. R&B though had an interesting year—with my scores and in general—with a high average score of 6.67 across six reviews.  Averages were calculated again for secondary and tertiary genres with similar results.

![My helpful screenshot]({{ "/assets/PrimaryGenre.PNG" | absolute_url }})

 
Next, I looked at how the country the song was from impacted by scores. Again, the data set is small and my reviews heavily favored Western countries with 59 of my 8 reviews coming just from the US and the UK. Again, those two countries tended toward my overall mean of 5.7. The data for the remaining countries is too small to draw meaningful insights from, but that is an encouragement for me to listen to more diverse music in 2018!

Finally, I looked at how the release year impacted my scoring, but with only 3 songs not being released in 2017, there was nothing too interesting here to say. The three songs from 2016 must have been good though, since they had an average score of 6.33.

Now, for a bit of fun, I tried to predict what my rating would be based knowledge of the artist, country, genres, release date, and length of the song. To do this, I experimented with a few different models. I ran each model 500 times and regenerated my testing and training data set each time with an 80/20 training/testing split. The accuracy was then averaged across each of the runs to evaluate the success of each model. Remember, the probability of success with random guess would be 1 in 11, or 0.0909 accuracy.

First, good old’ linear regression. I ran a standard Linear Regression (OLS) and a ridge regression, which yielded an accuracy of 0.1776 and 0.1769 respectively. Linear regression gave a result approximately twice as accurate as random guess.

Next, I tried two Naive Bayes models: Bernoulli and Gaussian. Bernoulli Naïve Bayes gave a 0.1571 accuracy and Gaussian a 0.1026, neither much better than random guess.

Next came classic k-nearest neighbors. Using k=3, the accuracy shot up to 0.1951—more than twice as accurate as random guess, on average.

Finally, I tried some more complex models using Decision Trees and Extra Trees classifiers, yielding 0.1750 and 0.1926 respectively.

model performance.PNG
Overall, k nearest neighbors yielded the best results, though even the accuracy here was far lower than would be typically be acceptable for a classification model. However, it is interesting to think about why k-nearest neighbor might work best for this data set. With a small and rather homogenous set of features, maybe k-nearest neighbors helps bring out similarities between genres or country of origin. Or, maybe it is so simplistic that it works where the other models overcomplicate.

Regardless, I had a blast listening to more music than ever in 2017, and I look forward to getting a larger data set by listening to even more in the upcoming year. Below are my top 10 highest rated songs, if you'd like to give them a listen. Code for this can be found on my Github: https://github.com/ashleyajohn/musicof2017!
